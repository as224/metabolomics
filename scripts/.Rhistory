cut_log <- log[(start_index + 1):(end_index - 2)]
# Split the lines into seperated cols (using spaces)
data <- strsplit(cut_log, "\\s+")
# Store in Data Frame
df <- as.data.frame(do.call(rbind, data), stringsAsFactors = FALSE)
colnames(df) <- df[1, ] # Col names
df <- df[-1,-1]  # Delete first row (names) and col (empty)
row.names(df) <- NULL # Reset indices
# Add ID column
# Extract p1 and p2
p1_p2 <- df[, 0:2]
# Extract substring right after third "_" and before ".sumstats.gz"
if(output_ld_regression_path == "../output_ld_regression"){
extract_substring <- function(string) {
sub("^(?:[^_]*_){3}", "", gsub(".sumstats.gz$", "", string))
}
} else if (output_ld_regression_path == "../output_ld_regression_significant_mergealleles") {
extract_substring <- function(string) {
sub("^(?:[^_]*_){6}", "", gsub(".sumstats.gz$", "", string))
}
} else if (output_ld_regression_path == "../output_ld_regression_significant") {
extract_substring <- function(string) {
sub("^(?:[^_]*_){4}", "", gsub(".sumstats.gz$", "", string))
} else {
print("Please give a valid output folder regression path!")
}
# Apply to p1 and p2
p1_p2 <- apply(p1_p2, 2, extract_substring)
# Add four cols to df
df$p1_id <- p1_p2[,1]
df$p2_id <- p1_p2[,2]
df$id <- paste(df$p1_id, df$p2_id, sep = "/")
df$method <- rep("ldsc", nrow(df))
# Replace NA with 0 for genetic correlation
df$rg <- as.numeric(df$rg)
df$rg[is.na(df$rg)] <- 0
# Add FDR
df$q <- p.adjust(df$p, method = "fdr")
# Return the df
return(df)
}
# Output of meeting (19.02.) -> don't cap the values >1 or <-1 but set the to zero!
# generate_df_capped <- function(input_df){
#   df_capped <- input_df
#   df_capped$rg[df_capped$rg > 1] <- 1
#   df_capped$rg[df_capped$rg < -1] <- -1
#   return(df_capped)
# }
# Initialize an empty data frame without specifying the number of rows
df_all <- data.frame(matrix(ncol = 16, nrow=0))
colnames(df_all) <- c("p1", "p2", "rg", "se", "z", "p", "h2_obs", "h2_obs_se", "h2_int", "h2_int_se", "gcov_int", "gcov_int_se", "p1_id", "p2_id", "id", "method")
files <- list.files(path = output_ld_regression_path, pattern = "\\ldReg.log$", full.names = TRUE)
for (file in files) {
input_file_path <- file
output_file_path <- gsub(".log", ".tsv", input_file_path)
# Call function
df <- generate_df(input = input_file_path)
# Write df to tsv file
write.table(df, file = output_file_path , sep = "\t", row.names = FALSE, quote=FALSE)
# Output of meeting (19.02.) -> don't cap the values >1 or <-1 but set the to zero!
# df_cap <- generate_df_capped(input_df = df)
# write.table(df_cap, file = paste("../output_ld_regression/capped_", basename(file), ".tsv", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)
# Append df to df_all
df_all <- rbind(df_all, df)
}
# Adjust the correlation values -> >1=0 and <-1=0 (the highest correlation (diagnoal values) is one -> thus a higher value than 1 explains something weird and also <-1)
df_all_adjusted <- df_all
df_all_adjusted$rg[df_all$rg > 1] <- 0
df_all_adjusted$rg[df_all$rg < -1] <- 0
# Create a matrix containing all correlation values (with adjusted correlation values -> >1, <-1 handeled)
df_aggregated <- df_all_adjusted %>%
group_by(p1_id, p2_id) %>%
summarise(rg = first(rg)) %>%
ungroup()
matrix_df <- spread(df_aggregated, key = p1_id, value = rg)
row_names <- matrix_df$p2_id
matrix_df$p2_id <- NULL
rownames(matrix_df) <- row_names
matrix_df <- as.matrix(matrix_df)
# Create a matrix containing all correlation values (with real correlation values)
df_aggregated_all <- df_all %>%
group_by(p1_id, p2_id) %>%
summarise(rg = first(rg)) %>%
ungroup()
matrix_df_woCorrection <- spread(df_aggregated_all, key = p1_id, value = rg)
row_names <- matrix_df_woCorrection$p2_id
matrix_df_woCorrection$p2_id <- NULL
rownames(matrix_df_woCorrection) <- row_names
matrix_df_woCorrection <- as.matrix(matrix_df_woCorrection)
# Save all created df's and matrices
write.table(df_all, file = paste(output_ld_regression_path, "/complete_df.tsv", sep="") , sep = "\t", row.names = FALSE, quote=FALSE)
write.table(df_all_adjusted, file = paste(output_ld_regression_path, "/complete_df_adjusted.tsv", sep="") , sep = "\t", row.names = FALSE, quote=FALSE)
write.table(matrix_df, file = paste(output_ld_regression_path, "/matrix_df.tsv", sep=""), row.names = TRUE, quote=FALSE)
write.table(matrix_df_woCorrection, file = paste(output_ld_regression_path, "/matrix_df_woCorrection.tsv", sep=""), row.names = TRUE, quote=FALSE)
# Load required libraries
#install.packages("readtext")
library("readtext")
library(tidyr)
library(dplyr)
library(tibble)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
output_ld_regression_path <- "../output_ld_regression"
#output_ld_regression_path <- "../output_ld_regression_significant_mergealleles"
# Function that generates tsv from log and adds cols (p1_id, p2_id, id and method)
generate_df <- function(input) {
log <- readLines(input)
# Start and end of table
start_index <- which(log == "Summary of Genetic Correlation Results")
end_index <- grep("^Analysis finished at", log)
cut_log <- log[(start_index + 1):(end_index - 2)]
# Split the lines into seperated cols (using spaces)
data <- strsplit(cut_log, "\\s+")
# Store in Data Frame
df <- as.data.frame(do.call(rbind, data), stringsAsFactors = FALSE)
colnames(df) <- df[1, ] # Col names
df <- df[-1,-1]  # Delete first row (names) and col (empty)
row.names(df) <- NULL # Reset indices
# Add ID column
# Extract p1 and p2
p1_p2 <- df[, 0:2]
# Extract substring right after third "_" and before ".sumstats.gz"
if(output_ld_regression_path == "../output_ld_regression"){
extract_substring <- function(string) {
sub("^(?:[^_]*_){3}", "", gsub(".sumstats.gz$", "", string))
}
} else if (output_ld_regression_path == "../output_ld_regression_significant_mergealleles") {
extract_substring <- function(string) {
sub("^(?:[^_]*_){6}", "", gsub(".sumstats.gz$", "", string))
}
} else if (output_ld_regression_path == "../output_ld_regression_significant") {
extract_substring <- function(string) {
sub("^(?:[^_]*_){4}", "", gsub(".sumstats.gz$", "", string))
}} else {
print("Please give a valid output folder regression path!")
}
# Apply to p1 and p2
p1_p2 <- apply(p1_p2, 2, extract_substring)
# Add four cols to df
df$p1_id <- p1_p2[,1]
df$p2_id <- p1_p2[,2]
df$id <- paste(df$p1_id, df$p2_id, sep = "/")
df$method <- rep("ldsc", nrow(df))
# Replace NA with 0 for genetic correlation
df$rg <- as.numeric(df$rg)
df$rg[is.na(df$rg)] <- 0
# Add FDR
df$q <- p.adjust(df$p, method = "fdr")
# Return the df
return(df)
}
# Output of meeting (19.02.) -> don't cap the values >1 or <-1 but set the to zero!
# generate_df_capped <- function(input_df){
#   df_capped <- input_df
#   df_capped$rg[df_capped$rg > 1] <- 1
#   df_capped$rg[df_capped$rg < -1] <- -1
#   return(df_capped)
# }
# Initialize an empty data frame without specifying the number of rows
df_all <- data.frame(matrix(ncol = 16, nrow=0))
colnames(df_all) <- c("p1", "p2", "rg", "se", "z", "p", "h2_obs", "h2_obs_se", "h2_int", "h2_int_se", "gcov_int", "gcov_int_se", "p1_id", "p2_id", "id", "method")
files <- list.files(path = output_ld_regression_path, pattern = "\\ldReg.log$", full.names = TRUE)
for (file in files) {
input_file_path <- file
output_file_path <- gsub(".log", ".tsv", input_file_path)
# Call function
df <- generate_df(input = input_file_path)
# Write df to tsv file
write.table(df, file = output_file_path , sep = "\t", row.names = FALSE, quote=FALSE)
# Output of meeting (19.02.) -> don't cap the values >1 or <-1 but set the to zero!
# df_cap <- generate_df_capped(input_df = df)
# write.table(df_cap, file = paste("../output_ld_regression/capped_", basename(file), ".tsv", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)
# Append df to df_all
df_all <- rbind(df_all, df)
}
# Adjust the correlation values -> >1=0 and <-1=0 (the highest correlation (diagnoal values) is one -> thus a higher value than 1 explains something weird and also <-1)
df_all_adjusted <- df_all
df_all_adjusted$rg[df_all$rg > 1] <- 0
df_all_adjusted$rg[df_all$rg < -1] <- 0
# Create a matrix containing all correlation values (with adjusted correlation values -> >1, <-1 handeled)
df_aggregated <- df_all_adjusted %>%
group_by(p1_id, p2_id) %>%
summarise(rg = first(rg)) %>%
ungroup()
matrix_df <- spread(df_aggregated, key = p1_id, value = rg)
row_names <- matrix_df$p2_id
matrix_df$p2_id <- NULL
rownames(matrix_df) <- row_names
matrix_df <- as.matrix(matrix_df)
# Create a matrix containing all correlation values (with real correlation values)
df_aggregated_all <- df_all %>%
group_by(p1_id, p2_id) %>%
summarise(rg = first(rg)) %>%
ungroup()
matrix_df_woCorrection <- spread(df_aggregated_all, key = p1_id, value = rg)
row_names <- matrix_df_woCorrection$p2_id
matrix_df_woCorrection$p2_id <- NULL
rownames(matrix_df_woCorrection) <- row_names
matrix_df_woCorrection <- as.matrix(matrix_df_woCorrection)
# Save all created df's and matrices
write.table(df_all, file = paste(output_ld_regression_path, "/complete_df.tsv", sep="") , sep = "\t", row.names = FALSE, quote=FALSE)
write.table(df_all_adjusted, file = paste(output_ld_regression_path, "/complete_df_adjusted.tsv", sep="") , sep = "\t", row.names = FALSE, quote=FALSE)
write.table(matrix_df, file = paste(output_ld_regression_path, "/matrix_df.tsv", sep=""), row.names = TRUE, quote=FALSE)
write.table(matrix_df_woCorrection, file = paste(output_ld_regression_path, "/matrix_df_woCorrection.tsv", sep=""), row.names = TRUE, quote=FALSE)
# Load required libraries
#install.packages("readtext")
library("readtext")
library(tidyr)
library(dplyr)
library(tibble)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#output_ld_regression_path <- "../output_ld_regression"
output_ld_regression_path <- "../output_ld_regression_significant_mergealleles"
# Function that generates tsv from log and adds cols (p1_id, p2_id, id and method)
generate_df <- function(input) {
log <- readLines(input)
# Start and end of table
start_index <- which(log == "Summary of Genetic Correlation Results")
end_index <- grep("^Analysis finished at", log)
cut_log <- log[(start_index + 1):(end_index - 2)]
# Split the lines into seperated cols (using spaces)
data <- strsplit(cut_log, "\\s+")
# Store in Data Frame
df <- as.data.frame(do.call(rbind, data), stringsAsFactors = FALSE)
colnames(df) <- df[1, ] # Col names
df <- df[-1,-1]  # Delete first row (names) and col (empty)
row.names(df) <- NULL # Reset indices
# Add ID column
# Extract p1 and p2
p1_p2 <- df[, 0:2]
# Extract substring right after third "_" and before ".sumstats.gz"
if(output_ld_regression_path == "../output_ld_regression"){
extract_substring <- function(string) {
sub("^(?:[^_]*_){3}", "", gsub(".sumstats.gz$", "", string))
}
} else if (output_ld_regression_path == "../output_ld_regression_significant_mergealleles") {
extract_substring <- function(string) {
sub("^(?:[^_]*_){6}", "", gsub(".sumstats.gz$", "", string))
}
} else if (output_ld_regression_path == "../output_ld_regression_significant") {
extract_substring <- function(string) {
sub("^(?:[^_]*_){4}", "", gsub(".sumstats.gz$", "", string))
}} else {
print("Please give a valid output folder regression path!")
}
# Apply to p1 and p2
p1_p2 <- apply(p1_p2, 2, extract_substring)
# Add four cols to df
df$p1_id <- p1_p2[,1]
df$p2_id <- p1_p2[,2]
df$id <- paste(df$p1_id, df$p2_id, sep = "/")
df$method <- rep("ldsc", nrow(df))
# Replace NA with 0 for genetic correlation
df$rg <- as.numeric(df$rg)
df$rg[is.na(df$rg)] <- 0
# Add FDR
df$q <- p.adjust(df$p, method = "fdr")
# Return the df
return(df)
}
# Output of meeting (19.02.) -> don't cap the values >1 or <-1 but set the to zero!
# generate_df_capped <- function(input_df){
#   df_capped <- input_df
#   df_capped$rg[df_capped$rg > 1] <- 1
#   df_capped$rg[df_capped$rg < -1] <- -1
#   return(df_capped)
# }
# Initialize an empty data frame without specifying the number of rows
df_all <- data.frame(matrix(ncol = 16, nrow=0))
colnames(df_all) <- c("p1", "p2", "rg", "se", "z", "p", "h2_obs", "h2_obs_se", "h2_int", "h2_int_se", "gcov_int", "gcov_int_se", "p1_id", "p2_id", "id", "method")
files <- list.files(path = output_ld_regression_path, pattern = "\\ldReg.log$", full.names = TRUE)
for (file in files) {
input_file_path <- file
output_file_path <- gsub(".log", ".tsv", input_file_path)
# Call function
df <- generate_df(input = input_file_path)
# Write df to tsv file
write.table(df, file = output_file_path , sep = "\t", row.names = FALSE, quote=FALSE)
# Output of meeting (19.02.) -> don't cap the values >1 or <-1 but set the to zero!
# df_cap <- generate_df_capped(input_df = df)
# write.table(df_cap, file = paste("../output_ld_regression/capped_", basename(file), ".tsv", sep = ""), sep = "\t", row.names = FALSE, quote = FALSE)
# Append df to df_all
df_all <- rbind(df_all, df)
}
# Adjust the correlation values -> >1=0 and <-1=0 (the highest correlation (diagnoal values) is one -> thus a higher value than 1 explains something weird and also <-1)
df_all_adjusted <- df_all
df_all_adjusted$rg[df_all$rg > 1] <- 0
df_all_adjusted$rg[df_all$rg < -1] <- 0
# Create a matrix containing all correlation values (with adjusted correlation values -> >1, <-1 handeled)
df_aggregated <- df_all_adjusted %>%
group_by(p1_id, p2_id) %>%
summarise(rg = first(rg)) %>%
ungroup()
matrix_df <- spread(df_aggregated, key = p1_id, value = rg)
row_names <- matrix_df$p2_id
matrix_df$p2_id <- NULL
rownames(matrix_df) <- row_names
matrix_df <- as.matrix(matrix_df)
# Create a matrix containing all correlation values (with real correlation values)
df_aggregated_all <- df_all %>%
group_by(p1_id, p2_id) %>%
summarise(rg = first(rg)) %>%
ungroup()
matrix_df_woCorrection <- spread(df_aggregated_all, key = p1_id, value = rg)
row_names <- matrix_df_woCorrection$p2_id
matrix_df_woCorrection$p2_id <- NULL
rownames(matrix_df_woCorrection) <- row_names
matrix_df_woCorrection <- as.matrix(matrix_df_woCorrection)
# Save all created df's and matrices
write.table(df_all, file = paste(output_ld_regression_path, "/complete_df.tsv", sep="") , sep = "\t", row.names = FALSE, quote=FALSE)
write.table(df_all_adjusted, file = paste(output_ld_regression_path, "/complete_df_adjusted.tsv", sep="") , sep = "\t", row.names = FALSE, quote=FALSE)
write.table(matrix_df, file = paste(output_ld_regression_path, "/matrix_df.tsv", sep=""), row.names = TRUE, quote=FALSE)
write.table(matrix_df_woCorrection, file = paste(output_ld_regression_path, "/matrix_df_woCorrection.tsv", sep=""), row.names = TRUE, quote=FALSE)
# This script creates a input_rg.txt file in order to be able to use ldsc-network-plot
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
folder_path = "../output_ld_regression_significant_mergealleles"
#folder_path = "../output_ld_regression"
# Einlesen der Datei
df_adjusted <- read.table(paste(folder_path, "/complete_df_adjusted.tsv", sep=""), header=TRUE)
df_adjusted <- subset(df_adjusted, select = -c(p1 , p2))
# Adjust column names
# TODO adjust p1_category and p2_category
colnames(df_adjusted)[colnames(df_adjusted) == "p1_id"] <- "p1"
colnames(df_adjusted)[colnames(df_adjusted) == "p2_id"] <- "p2"
trait_category_mapping <- c("IL" = "Cytokine",
"MS" = "Autoimmune",
"ALS" = "Autoimmune",
"bNGF" = "Protein",
"CTACK" = "Cytokine",
"eotaxin" = "Cytokine",
"GCSF" = "Protein",
"FGF" = "Protein",
"GROa" = "Cytokine",
"IFNg" = "Cytokine",
"ip10" = "Protein",
"MCP" = "Protein",
"MCSF" = "Cytokine",
"MIF" = "Cytokine",
"MIG" = "Cytokine",
"MIP" = "Cytokine",
"PDGFbb" = "Protein",
"RANTES" = "Cytokine",
"SCF" = "Cytokine",
"SCGFb" = "Protein",
"SDF1" = "Cytokine",
"TNF" = "Cytokine",
"TRAIL" = "Cytokine",
"T2D" = "Autoimmune",
"PD" = "Autoimmune",
"RA" = "Inflammatory",
"DLB" = "Inflammatory",
"SCZ" = "Inflammatory",
"C3" = "Protein",
"HGF" = "Protein",
"MCP1" = "Protein",
"CRP" = "Protein")
for (key in names(trait_category_mapping)) {
# Find indices where TRAIT starts with the key
indices_p1 <- grepl(paste0("^", key), df_adjusted$p1)
indices_p2 <- grepl(paste0("^", key), df_adjusted$p2)
# Update CATEGORY with corresponding value from trait_category_mapping
df_adjusted$p1_category[indices_p1] <- trait_category_mapping[key]
df_adjusted$p2_category[indices_p2] <- trait_category_mapping[key]
}
df_adjusted <- subset(df_adjusted, p1 != p2)
df_adjusted <- subset(df_adjusted, select = c("p1_category", "p1", "p2_category", "p2", "rg", "se", "z", "p", "q"))
df_filtered <- df_adjusted[df_adjusted$rg != 0, ]
#write.table(df_adjusted, file = paste(folder_path, "/input_rg_categories.txt", sep=""), sep = "\t", row.names = FALSE, col.names = TRUE, quote = FALSE)
write.table(df_filtered, file = paste(folder_path, "/input_rg_categories_filtered.txt", sep=""), sep = "\t", row.names = FALSE, col.names = TRUE, quote = FALSE)
# This script creates a input_rg.txt file in order to be able to use ldsc-network-plot
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
#folder_path = "../output_ld_regression_significant_mergealleles"
folder_path = "../output_ld_regression"
# Einlesen der Datei
df_adjusted <- read.table(paste(folder_path, "/complete_df_adjusted.tsv", sep=""), header=TRUE)
df_adjusted <- subset(df_adjusted, select = -c(p1 , p2))
# Adjust column names
# TODO adjust p1_category and p2_category
colnames(df_adjusted)[colnames(df_adjusted) == "p1_id"] <- "p1"
colnames(df_adjusted)[colnames(df_adjusted) == "p2_id"] <- "p2"
trait_category_mapping <- c("IL" = "Cytokine",
"MS" = "Autoimmune",
"ALS" = "Autoimmune",
"bNGF" = "Protein",
"CTACK" = "Cytokine",
"eotaxin" = "Cytokine",
"GCSF" = "Protein",
"FGF" = "Protein",
"GROa" = "Cytokine",
"IFNg" = "Cytokine",
"ip10" = "Protein",
"MCP" = "Protein",
"MCSF" = "Cytokine",
"MIF" = "Cytokine",
"MIG" = "Cytokine",
"MIP" = "Cytokine",
"PDGFbb" = "Protein",
"RANTES" = "Cytokine",
"SCF" = "Cytokine",
"SCGFb" = "Protein",
"SDF1" = "Cytokine",
"TNF" = "Cytokine",
"TRAIL" = "Cytokine",
"T2D" = "Autoimmune",
"PD" = "Autoimmune",
"RA" = "Inflammatory",
"DLB" = "Inflammatory",
"SCZ" = "Inflammatory",
"C3" = "Protein",
"HGF" = "Protein",
"MCP1" = "Protein",
"CRP" = "Protein")
for (key in names(trait_category_mapping)) {
# Find indices where TRAIT starts with the key
indices_p1 <- grepl(paste0("^", key), df_adjusted$p1)
indices_p2 <- grepl(paste0("^", key), df_adjusted$p2)
# Update CATEGORY with corresponding value from trait_category_mapping
df_adjusted$p1_category[indices_p1] <- trait_category_mapping[key]
df_adjusted$p2_category[indices_p2] <- trait_category_mapping[key]
}
df_adjusted <- subset(df_adjusted, p1 != p2)
df_adjusted <- subset(df_adjusted, select = c("p1_category", "p1", "p2_category", "p2", "rg", "se", "z", "p", "q"))
df_filtered <- df_adjusted[df_adjusted$rg != 0, ]
#write.table(df_adjusted, file = paste(folder_path, "/input_rg_categories.txt", sep=""), sep = "\t", row.names = FALSE, col.names = TRUE, quote = FALSE)
write.table(df_filtered, file = paste(folder_path, "/input_rg_categories_filtered.txt", sep=""), sep = "\t", row.names = FALSE, col.names = TRUE, quote = FALSE)
# This file is for checking the significance of the given 61 GWAS studies.
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# Create a list that contains all the input files (regarding single_GWAS folder)
# Prerequisite: Please download the folders at google drive (called singleGWAS and cytokines) into "input_files"
folder_singleG <- "../input_files/single_GWAS"
filelist_singleG <- list.files(folder_singleG, pattern = "\\.tsv\\.gz$", full.names = TRUE)
# Create a list that contains all the input files (regarding cytokine folder)
folder_cytokine <- "../input_files/cytokines"
filelist_cytokine <- list.files(folder_cytokine, pattern = "\\.tsv\\.gz$", full.names = TRUE)
# Combine both lists that contain the input files
combined_filelist <- c(filelist_singleG, filelist_cytokine)
# Location of the folder where the included studies should be stored
included_folderpath <- "../input_files/significant_cytokines_singleGWAS"
# Check if the folder exists
if (!dir.exists(included_folderpath)) {
# Create it if not existent
dir.create(included_folderpath, recursive = TRUE)
print(paste("Folder", included_folderpath, "created."))
} else {
print(paste("Folder", included_folderpath, "already exists."))
}
# List with files that stores the included studies
included_files <- c()
# Go through every file
for (file in combined_filelist) {
print(file)
data <- read.delim(file)
# Check for NA values in "pvalue" column
amount_na_rows <- sum(is.na(data$pvalue))
if(amount_na_rows == nrow(data)){
next # Next if all p values are equal to NA -> Exclude the study
}
# Check if p values are < 5*10e-8.
small_pvalues <- sum(data$pvalue < 5*10e-8)
if(small_pvalues == 0){
next # If all p values are >= 5*10e-8 -> Exclude the study.
}
else {
subset_data <- data[data$pvalue < 5*10e-8, ] # Create a data frame that only contains significant p values.
# Check if there is only one SNP that fulfills the condition -> Exclude the study.
if(nrow(subset_data) == 1){
next
}
# Go through every SNP that meets the condition: pvalue < 5*10e-8
for (i in 1:(nrow(subset_data) - 1)) {
# Get the current SNP
current_snp <- subset_data[i, ]
if(is.na(current_snp$SNP)){
next # Skip the SNP if the SNP id is NA
}
# Flag to check if a pair of SNPs meeting the condition is found
pair_found <- FALSE
# Iterate through all the other SNPs
for (j in (i + 1):nrow(subset_data)) {
# Get the next SNP (don't compare a SNP to itself -> because this is either way not significant)
next_snp <- subset_data[j, ]
if(is.na(next_snp$SNP)){
next # Skip the SNP if the SNP id is NA
}
if (!is.na(current_snp$chr) && !is.na(next_snp$chr)) {
if (current_snp$chr != next_snp$chr) {
pair_found <- TRUE
} else { # If the SNPs are on the same chromosome: Check if the bp are > 1e6 away -> Include the study
if (!is.na(current_snp$bp_38) && !is.na(next_snp$bp_38)) {
if (abs(next_snp$bp_38 - current_snp$bp_38) > 1e6) {
pair_found <- TRUE
}
}
}
} # end of if condition
# If a pair is found, exit the loop -> Include the study
if (pair_found) {
included_files <- c(included_files, file) # add the study to the list for analyizing it further
break
}
}
# If a pair is found, exit the outer loop -> Include the study
if (pair_found) {
break
}
} # end of outer for loop
} # end of else condition
}
destination_folder <- "../input_files/significant_cytokines_singleGWAS"
# Loop through each file path in the list and copy it to the destination folder
for (file_path in included_files) {
file.copy(file_path, destination_folder)
}
